---
title: "Classification II"
---

## Summary

Advanced this week!ÔºÅüòÑ

We learned more advanced remote sensing classification methods, mainly **Object Oriented Image Analysis (OBIA)** and **Subpixel Classification**. Compared to the pixel-level classification we used before, this time the focus is on how to extract information from more complex remote sensing data, such as analysing the proportion of features at the sub-pixel level by using **Spectral Mixture Analysis (SMA)** or clustering similar pixels by using **Super Pixel Segmentation (SNIC)**.

The practical part is still GEE, this time with Landsat data instead, we first did a wave of routine operations (loading data, cloud mask, image cropping), and then tried **Spectral Unmixing (Linear Spectral Unmixing)**. The core idea of this method is to pick a few endmembers (endmembers) and then calculate the percentage of land coverage for each pixel. After that, I also did a wave of classification using the SNIC superpixel method, and the result was better than the simple pixel-level classification.

## Application

1.  The classification methods we learned this week are particularly effective for¬†**Urban Sprawl Monitoring**¬†and¬†**Land Use Mapping**. Compared to pixel-level classification,¬†**Object-Based Image Analysis (OBIA)**¬†can group pixels into meaningful regions‚Äîlike high-density residential areas, commercial zones, and green spaces‚Äîmaking the output much more interpretable and less noisy.

    To better understand how OBIA differs from traditional pixel-based classification, I created a simple visual comparison:

    ```{r pixel-vs-obia, fig.cap="Pixel vs Object-based Classification", fig.align="center"}
    library(ggplot2)
    library(reshape2)
    library(gridExtra)

    pixel <- matrix(sample(1:3, 100, replace=TRUE), ncol=10)
    obia <- matrix(c(rep(1,25), rep(2,25), rep(3,25), rep(4,25)), ncol=10)

    p1 <- ggplot(melt(pixel), aes(x=Var1, y=Var2, fill=factor(value))) + 
      geom_tile(color="white") + 
      scale_fill_brewer(palette="Set2") + 
      coord_equal() + 
      labs(title="Pixel-level Classification") + 
      theme_void() + theme(legend.position="none")

    p2 <- ggplot(melt(obia), aes(x=Var1, y=Var2, fill=factor(value))) + 
      geom_tile(color="white") + 
      scale_fill_brewer(palette="Set3") + 
      coord_equal() + 
      labs(title="Object-based Classification") + 
      theme_void() + theme(legend.position="none")

    grid.arrange(p1, p2, ncol=2)
    ```

    When I previously used Random Forest with pixel-level data, the results sometimes felt scattered or imprecise, especially at class boundaries. Now, with additional spatial context from OBIA or SNIC segmentation, the urban structures are more coherent and the classification results feel much more reliable.

2.  **Forest monitoring** is also a typical application, especially for illegal logging detection. Traditional pixel-level classification may misclassify mixed pixels (e.g. partially deforested forests), but SMA, a spectral mixing method, can more accurately estimate the proportion of canopy cover, for example, the destruction of the Amazon rainforest can be analysed with Landsat data, providing more accurate information to environmental organisations.

3.  **Water Management** can also use subpixel classification. For example, with Sentinel-2 data, we can analyse the different components in a body of water, like suspended sediment, algae and so on, which is still quite effective for pollution source monitoring. Wouldn't it be more intuitive for a coastal city to use this method to track the spread of pollution than traditional water quality monitoring?

## Reflection

The *biggest* takeaway from this week is that classification is not just about choosing an algorithm, it's more about using the right method. Pixel-level classification is simple and rough, but sometimes a lot of details will be lost, especially the problem of mixed pixels, OBIA and SMA can analyse the image in more detail, especially SNIC, which is a super-pixel method, a little bit similar to K-means, but it can make the spatial structure more reasonable, and the classification effect is obviously better.

In the part of classification accuracy evaluation, the previous modelling only focuses on Overall Accuracy (OA), but actually **Producer's Accuracy and User's Accuracy** are more important. For example, if the mapping accuracy of the ‚Äògreen space‚Äô category in the classification is very low, urban planners may make wrong decisions with this data. So, when evaluating a classification model, you should not just look at one metric, but consider all aspects.

**Next (in the future)ü™Å:**

I would like to try deep learning (e.g. CNN) on remote sensing classification to see if the accuracy can be further improved. At the same time, I also want to figure out the effect of end-element selection on spectral mixture analysis, and try different methods to optimise the classification effect. This week's study made me realise that remote sensing classification is not just as simple as running a model, but more about finding a solution suitable for practical applications.
